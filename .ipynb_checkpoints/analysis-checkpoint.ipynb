{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Vector Featues\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from svm_classifier import getClassifierAndVectorizer\n",
    "import numpy as np\n",
    "import glob, os, pickle\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.patches import Polygon\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported correctly\n"
     ]
    }
   ],
   "source": [
    "clf, vectorizer = getClassifierAndVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractor(n=10000):\n",
    "    #n is number of opinions from each year\"\n",
    "    filename = \"sentences_new/\"\n",
    "    datafiles = sorted(glob.glob(filename + \"sent_????\"))\n",
    "    test_files = []\n",
    "    year = []\n",
    "    cases_per_year = []\n",
    "    y = 1891\n",
    "    case_names = []\n",
    "    a = 0\n",
    "    for d in datafiles:\n",
    "        sentences = sorted(glob.glob(d + \"/*.txt\"))\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i >= n:\n",
    "                break\n",
    "            myfile = open(sentence,'r') \n",
    "            data=myfile.read().replace('\\n', '')\n",
    "            test_files.append(data)\n",
    "            year.append(y)\n",
    "\n",
    "            #adding case no and judge no.\n",
    "            case_n = \"\"\n",
    "            flag = False\n",
    "            for j in sentence:\n",
    "                if j == \"X\":\n",
    "                    flag = True\n",
    "                if j == \"_\":\n",
    "                    flag = False\n",
    "                if j == \".\":\n",
    "                    flag = False\n",
    "                if flag == True:\n",
    "                    case_n += j\n",
    "            case_names.append(case_n)\n",
    "\n",
    "            myfile.close()\n",
    "        cases_per_year.append(len(sentences))\n",
    "        y += 1\n",
    "    print(a)\n",
    "    return test_files, year, cases_per_year, case_names\n",
    "\n",
    "def loadDataset(pklPath):\n",
    "    with open(pklPath, \"rb\") as pklFile:\n",
    "        return np.array(pickle.load(pklFile, encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported correctly\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#x_test = vectorizer.transform(data_to_predict)\n",
    "clf, vectorizer = getClassifierAndVectorizer()\n",
    "cases, year_of_case, cases_per_year, case_names = extractor()\n",
    "x_test = vectorizer.transform(cases)\n",
    "prediction = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported correctly\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "clf, vectorizer = getClassifierAndVectorizer()\n",
    "cases, year_of_case, cases_per_year, case_names = extractor()\n",
    "x_test = vectorizer.transform(cases)\n",
    "prediction = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cases, year_of_case, cases_per_year, case_names = extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractorForPara(n=10000):\n",
    "    #n is number of opinions from each year\"\n",
    "    filename = \"paragraphs/\"\n",
    "    datafiles = sorted(glob.glob(filename + \"para_????\"))\n",
    "    test_files = []\n",
    "\n",
    "    for d in datafiles:\n",
    "        paragraphs = sorted(glob.glob(d + \"/*.pkl\"))\n",
    "        for i, para in enumerate(paragraphs):\n",
    "            if i > n:\n",
    "                break\n",
    "            myfile = loadDataset(para)\n",
    "            for j in myfile:\n",
    "                if len(j) > 200:\n",
    "                    test_files.append(j)\n",
    "\n",
    "    return test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = extractorForPara()\n",
    "x_test_para = vectorizer.transform(paragraphs)\n",
    "prediction_para = clf.predict(x_test_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rank paragraohs\n",
    "\n",
    "\n",
    "\n",
    "proba = clf.decision_function(x_test_para)\n",
    "temp_proba = proba.copy().tolist()\n",
    "\n",
    "consPara = []\n",
    "deonPara = []\n",
    "\n",
    "for i in range(100):\n",
    "    #range determines how many 'top' paragraphs to find\n",
    "    max_val = max(temp_proba)\n",
    "    max_index = temp_proba.index(max_val)\n",
    "\n",
    "    min_val = min(temp_proba)\n",
    "    min_index = temp_proba.index(min_val)\n",
    "\n",
    "    consPara.append(min_index)\n",
    "    deonPara.append(max_index)\n",
    "\n",
    "    temp_proba[max_index], temp_proba[min_index] = 0, 0\n",
    "\n",
    "print(len(consPara))\n",
    "print(\"Strongly Consequentialist\")\n",
    "for i in range(10):\n",
    "    print(paragraphs[consPara[i]])\n",
    "    print('\\n')\n",
    "print(\"Strongly Deontologist\")\n",
    "for j in range(10):\n",
    "    print(paragraphs[deonPara[j]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, j in zip(attrib, prediction):\n",
    "#        print('%r => %s' % (i, j))\n",
    "\n",
    "#consPerYear = dict((yr,0) for yr in range(1891, 2014)) \n",
    "#deonPerYear = dict((yr,0) for yr in range(1891, 2014))\n",
    "years = range(1891,2014)\n",
    "consPerYear, deonPerYear = np.zeros(len(years)), np.zeros(len(years))\n",
    "for i, j in zip(year_of_case, prediction):\n",
    "    if j == \"cons\":\n",
    "        consPerYear[i - 1891] += 1\n",
    "    if j == \"deon\":\n",
    "        deonPerYear[i - 1891] += 1\n",
    "        \n",
    "        \n",
    "plt.plot(years, consPerYear, 'r')\n",
    "#plt.plot(years, deonPerYear)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [] #consPerYear / cases_per_year\n",
    "for i, j in zip(consPerYear, cases_per_year):\n",
    "    if j < 10000:\n",
    "        percentages.append(i/float(j))\n",
    "    else:\n",
    "        percentages.append(i/100)\n",
    "plt.plot(years, percentages)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Percentage of Cases with Cons Reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MajVsDisExtractor():\n",
    "\n",
    "    filename = \"sentences_new/\"\n",
    "    datafiles = sorted(glob.glob(filename + \"sent_????\"))\n",
    "    test_files = []\n",
    "    maj_op = []\n",
    "    dis_op = []\n",
    "\n",
    "    d = datafiles[1922-1891]\n",
    "    sentences = sorted(glob.glob(d + \"/*.txt\"))\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        myfile = open(sentences[i],'r')\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "        if \"MajOp\" in sentences[i]:\n",
    "            maj_op.append(data)\n",
    "        elif \"DisOp\" in sentences[i]:\n",
    "            dis_op.append(data)\n",
    "    \n",
    "        myfile.close()\n",
    "    return maj_op, dis_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majOp, disOp = MajVsDisExtractor()\n",
    "majTest = vectorizer.transform(majOp)\n",
    "predictionMaj = clf.predict(majTest)\n",
    "disTest = vectorizer.transform(disOp)\n",
    "predictionDis = clf.predict(disTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "majOp, disOp = MajVsDisExtractor()\n",
    "majTest = vectorizer.transform(majOp)\n",
    "predictionMaj = clf.predict(majTest)\n",
    "disTest = vectorizer.transform(disOp)\n",
    "predictionDis = clf.predict(disTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentMajCons = predictionMaj.tolist().count('cons') / len(majOp)\n",
    "percentDisCons = predictionDis.tolist().count('cons') / len(disOp)\n",
    "plt.bar(\"Majority\", percentMajCons)\n",
    "plt.bar(\"Dissenting\", percentDisCons)\n",
    "print(percentMajCons)\n",
    "print(percentDisCons)\n",
    "#1922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plots we want to make\n",
    "\n",
    "\n",
    "#percentage of cons reasoning before and after econ seminar\n",
    "#judge reasoning over time (do judges stay persistently deon/cons?)\n",
    "#deon/cons vs educational instiution\n",
    "#deon/cons vs location?\n",
    "#deon/cons for topics (how do we identify topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataset(pklPath):\n",
    "    with open(pklPath, \"rb\") as pklFile:\n",
    "        return np.array(pickle.load(pklFile, encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataset(pklPath):\n",
    "    with open(pklPath, \"rb\") as pklFile:\n",
    "        return np.array(pickle.load(pklFile, encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genis = loadDataset(\"/Users/liammeier/moral-reasoning/bb2genis.pkl\")\n",
    "md = pd.read_stata(\"/Users/liammeier/moral-reasoning/circuit_metadata_excerpt.dta\") #md for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metadata['songername'])\n",
    "#print(df.keys())\n",
    "#print(type(df))\n",
    "print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md.keys()\n",
    "md = md.set_index('caseid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = md.loc['XB0OIFQNB5G0']\n",
    "print(c)\n",
    "a = md.loc['XB0OIFQNB5G0']['Author'].iloc[0]\n",
    "print(a)\n",
    "s = c['songername']\n",
    "for i, name in enumerate(s):\n",
    "    if a in name:\n",
    "        correctName = name\n",
    "\n",
    "print(correctName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case_songername = []\n",
    "bad_cases = []\n",
    "for case in case_names:\n",
    "    try:\n",
    "        c =  md.loc[case]\n",
    "        author = c['Author'].iloc[0]\n",
    "        songername = c['songername']\n",
    "        for i, name in enumerate(songername):   \n",
    "            if author in name:\n",
    "                correctName = name\n",
    "            #if author == '' and name != '':\n",
    "            #    correctName = name\n",
    "        case_songername.append(correctName)\n",
    "    except:\n",
    "        case_songername.append(-1)\n",
    "        bad_cases.append(case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(case_names)\n",
    "print(len(case_songername))\n",
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bios = pd.read_stata(\"/Users/liammeier/moral-reasoning/JudgesBioReshaped_TOUSE.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bios = bios.set_index('songername')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['birthyear']\n",
    "#print(case_songername[0])\n",
    "j = bios.loc[case_songername[0]]\n",
    "print(j.loc['birthyear'])\n",
    "\n",
    "def makeAtrList(atr):\n",
    "    listToReturn = []\n",
    "    for name in case_songername:\n",
    "        try:\n",
    "            judge = bios.loc[name]\n",
    "            listToReturn.append(judge.loc[atr])\n",
    "        except:\n",
    "            listToReturn.append(-1)\n",
    "    return listToReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributes = ['birthyear', 'presidentname', 'genderNew', 'nameofschool1', 'nameofschool2', 'nameofschool3', 'nameofschool4', 'nameofschool5',\n",
    "              'raceorethnicity', 'partyaffiliationofpresident', 'placeofbirthstate']\n",
    "atr = dict()    \n",
    "for a in attributes:\n",
    "    atr[a] = makeAtrList(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(atr)\n",
    "#for key, value in atr.items():\n",
    "#    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appointing President Party Affiliation\n",
    "partyList = atr['partyaffiliationofpresident']\n",
    "repCons = 0\n",
    "demCons = 0\n",
    "numRep = 0\n",
    "numDem = 0\n",
    "for i, j in zip(partyList, prediction):\n",
    "    if i == \"Democratic\":\n",
    "        numDem += 1\n",
    "        if j == \"cons\":\n",
    "            demCons +=1\n",
    "    elif i == \"Republican\":\n",
    "        numRep += 1\n",
    "        if j == \"cons\":\n",
    "            repCons +=1\n",
    "\n",
    "plt.bar(\"Democratic\", (demCons/numDem), color='b',)\n",
    "plt.bar(\"Republican\", (repCons/numRep), color='r')\n",
    "plt.ylabel(\"Percentage Consequentialist\")\n",
    "plt.xlabel(\"Party of Appointing President\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Gender\n",
    "genderList = atr['genderNew']\n",
    "femCons = 0\n",
    "malCons = 0\n",
    "numFem = 0\n",
    "numMal = 0\n",
    "for i, j in zip(genderList, prediction):\n",
    "    if i == \"M\":\n",
    "        numMal += 1\n",
    "        if j == \"cons\":\n",
    "            malCons +=1\n",
    "    elif i == \"F\":\n",
    "        numFem += 1\n",
    "        if j == \"cons\":\n",
    "            femCons +=1\n",
    "\n",
    "plt.bar(\"Female\", (femCons/numFem), color='pink',)\n",
    "plt.bar(\"Male\", (malCons/numMal), color='b')\n",
    "plt.ylabel(\"Percentage Consequentialist\")\n",
    "plt.xlabel(\"Gender of Judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school1 = atr['nameofschool1']\n",
    "school2 = atr['nameofschool2']\n",
    "school3 = atr['nameofschool3']\n",
    "school4 = atr['nameofschool4']\n",
    "school5 = atr['nameofschool5']\n",
    "\n",
    "schoolSet = set(school1+school2+school3+school4+school5)\n",
    "schoolCons = dict()\n",
    "#schoolTotal = dict(schoolSet)\n",
    "schoolTotal = dict.fromkeys(schoolSet, 0)\n",
    "schoolCons = dict.fromkeys(schoolSet, 0)\n",
    "\n",
    "#assuming last school attended is the law school\n",
    "\n",
    "for a, b, c, d, e, pred in zip(school1, school2, school3, school4, school5, prediction):\n",
    "    if e != '':\n",
    "        schoolTotal[e] += 1\n",
    "        if pred == 'cons':\n",
    "            schoolCons[e] += 1\n",
    "    elif d != '':\n",
    "        schoolTotal[d] += 1\n",
    "        if pred == 'cons':\n",
    "            schoolCons[d] += 1\n",
    "    elif c != '':\n",
    "        schoolTotal[c] += 1\n",
    "        if pred == 'cons':\n",
    "            schoolCons[c] += 1\n",
    "    elif b != '':\n",
    "        schoolTotal[b] += 1\n",
    "        if pred == 'cons':\n",
    "            schoolCons[b] += 1\n",
    "    elif a != '':\n",
    "        schoolTotal[a] += 1\n",
    "        if pred == 'cons':\n",
    "            schoolCons[a] += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#for s in schoolSet:\n",
    "#    schoolTotal[s] = school.count(s)\n",
    "   \n",
    "#for i, j in zip(school, prediction):\n",
    "#    schoolCons[i] = 0\n",
    "    \n",
    "#for i, j in zip(school, prediction):\n",
    "#    if j == 'cons':\n",
    "#        schoolCons[i] += 1\n",
    "total = sum(schoolTotal.values())\n",
    "consTotal = sum(schoolCons.values())\n",
    "overallPercentage = consTotal / total\n",
    "percentDict = dict()\n",
    "#come back and add n = ...\n",
    "for i in schoolTotal.keys():\n",
    "    if schoolTotal[i] > 1000:\n",
    "        p = schoolCons[i]/schoolTotal[i]\n",
    "        percentDict[i] = p / overallPercentage - 1\n",
    "\n",
    "\n",
    " \n",
    "#x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n",
    "sorted_percentDict = sorted(percentDict.items(), key=operator.itemgetter(1))\n",
    "for i in sorted_percentDict:\n",
    "    print(i)\n",
    "\n",
    "#print(sorted_percentDict)\n",
    "        \n",
    "#print(schoolTotal)\n",
    "#print(schoolCons)\n",
    "'''\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in schoolTotal.keys():\n",
    "    if schoolTotal[i] > 1000:\n",
    "        plt.bar(i, schoolCons[i]/schoolTotal[i])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = bios.loc['ADAMS, HENRY LEE']\n",
    "print(a)\n",
    "#for i, j in zip(a.keys(), a):\n",
    "#    print(i, \"-->\" , j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#birthyear, nameofschool1, degree_law, raceorethnicity, placeofbirthstate, partyaffiliationofrenompres, genderNew, party\n",
    "# political_party,\n",
    "states = atr['placeofbirthstate']\n",
    "\n",
    "stateSet = set(states)\n",
    "stateTotal = dict.fromkeys(stateSet, 0)\n",
    "stateCons = dict.fromkeys(stateSet, 0)\n",
    "\n",
    "for state, pred in zip(states, prediction):\n",
    "    if state != '':\n",
    "        stateTotal[state] += 1\n",
    "        if pred == 'cons':\n",
    "            stateCons[state] += 1\n",
    "            \n",
    "statePercentages = {s:(stateCons[s]/stateTotal[s]) for s in stateSet}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "# draw state boundaries.\n",
    "# data from U.S Census Bureau\n",
    "# http://www.census.gov/geo/www/cob/st2000.html\n",
    "shp_info = m.readshapefile('st99_d00','states',drawbounds=True)\n",
    "# population density by state from\n",
    "# http://en.wikipedia.org/wiki/List_of_U.S._states_by_population_density\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "}\n",
    "\n",
    "colors={}\n",
    "statenames=[]\n",
    "cmap = plt.cm.bwr # use 'hot' colormap\n",
    "vmin = .46; vmax = 1 # set range.\n",
    "#print(m.states_info)\n",
    "for shapedict in m.states_info:\n",
    "    statename = shapedict['NAME']\n",
    "    # skip DC and Puerto Rico.\n",
    "    if statename not in ['District of Columbia','Puerto Rico']:\n",
    "        #change state name to stae initials\n",
    "        state_initial = us_state_abbrev[statename]\n",
    "        pop = statePercentages[state_initial]\n",
    "        # calling colormap with value between 0 and 1 returns\n",
    "        # rgba value.  Invert color range (hot colors are high\n",
    "        # population), take sqrt root to spread out colors more.\n",
    "        #colors[statename] = cmap(1.-(np.sqrt((pop-vmin)/(vmax-vmin))))[:3]\n",
    "        colors[statename] = cmap((pop-vmin)/(vmax-vmin))\n",
    "    statenames.append(statename)\n",
    "# cycle through state names, color each one.\n",
    "ax = plt.gca() # get current axes instance\n",
    "for nshape,seg in enumerate(m.states):\n",
    "    # skip DC and Puerto Rico.\n",
    "    if statenames[nshape] not in ['District of Columbia','Puerto Rico']:\n",
    "        color = rgb2hex(colors[statenames[nshape]]) \n",
    "        poly = Polygon(seg,facecolor=color,edgecolor=color)\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "#plt.colorbar(m)\n",
    "#plt.colorbar()\n",
    "plt.title('Filling State Polygons by Consequentialist percentage')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
