Joshua Greene’s fMRI-based research on moral intuiting suggests to him a variety of quite important theses: first, that deontology should be thought of as a psychological natural kind, supervening on intuitions generated by mental mechanisms which can be identified in the brain; second, that since the deontological natural kind supervenes on our unreliable emotional centers, deontology is thereby undermined as a moral system; third, that deontology as a philosophical system should be seen as a post-hoc rationalization for our deontological “alarm bell” emotional responses.1
In this paper I argue that Greene’s research, although fascinating for many reasons, doesn’t undermine deontological moral philosophy. This is because both sentimentalist and rationalist moral epistemologies, applied to deontological value, predict exactly the data Greene has found. My discussion proceeds in three steps. In the first section I summarize Greene’s brief against deontology. In the second section I draw on standard accounts of moral emotions to suggest that there are ‘deontological emotions’ made rational by appearances of ‘deontological value.’ Finally, I outline a modest but realist intuitionist account of moral intuitions that connects deontological emotion to putative deontological value in a way that predicts Greene’s findings. (Since less robustly-realistic/more anti-realistic metaethical accounts would be only easier to argue for,2 a plausible account of wholly mind-independent deontological value will serve to underline the fact that Greene’s fMRI-based objections aren’t probative.)
2. Deontology as a Natural Kind?
Because of space limitations, I will presume the reader has a working knowledge of Greene’s experiments, highlights of which include the following:
• Moral dilemma cases involving impersonal harm for others (such as Foot’s Trolley case and Thomson’s Loop variant) are set against cases involving personal, up-close harm (e.g., Thomson’s Footbridge variant).3
107
Dan Demetriou
• In moral dilemmas involving impersonal harm, subjects display more activity in classically “cognitive” areas of the brain (the dorsolateral prefrontal cortex and parietal lobes).
• In moral dilemmas involving personal harm, subjects display more brain activity in areas associated with emotion (posterior cingulated cortex, the medial prefrontal cortex, and the amygdala).
• Subjects who give deontological responses in the personal harm cases tend to answer more quickly, when the emotional centers are more active, whereas subjects who give consequentialist answers tend to answer more slowly, after the sluggish cognitive centers become more active than the more responsive emotional centers.
I will also assume that the reader is familiar with the conclusions Greene draws from this research, i.e., that deontological ethical theory—which he feels is committed to obedience to certain endorsed moral principles or rules (Greene, 2007a, p. 37)—is really an elaborate post-hoc explanation for particularly powerful emotions which play an “alarm bell” role, telling us not to do something whatever the costs (Greene, 2007a, p. 63). These emotions are not reliable (since, e.g., there isn’t any plausible moral difference between Footbridge and Loop) and moreover are undermined by the fairly worked-out evolutionary explanations for their existence. The debunking explanation for deontological emotion, in short, is that our deontological sensibilities are grounded in areas in the brain evolved to deliver generally fitness-enhancing behaviors with a minimum amount of processing. Whatever the merits of these heuristics in the primitive circumstances in which they were formed (in which cooperation was iterated, in which all those we could help or harm were local, etc.), circumstances have since changed. Today we can now help and harm faceless others on the other side of the globe, and we must make policy decisions with long-term and serious consequences. As long as we continue to rely on our obsolete emotional centers we will not accurately track matters of genuine moral relevance.4
3. Deontology as a Thesis about Second-Order Values
It might be worthwhile to begin by briefly addressing two concerns raised by Greene which occlude the main issue. First, showing that some mental module has been evolved for fitness-enhancing purposes should not count as strong evidence to doubt the deliverances of said module. Every module we have is ultimately the product of fitness-enhancing pressures—including our “cognitive” ones; to doubt some, but not all, is unfair absent some special reason for doing so.5 Whatever generates deontological “alarm bell” emotions is no more suspect, then, than whatever mechanism generates the sort of emotions that Greene feels are complicit in utilitarian intuitions (see
108

A Modest Intuitionist Reply to Greene
the empirical-based studies of moral intuition by Jonathan Haidt et al. on precisely that issue).6
The second point worth bearing in mind is that, even if deontologists allow (as I claim below they should) that deontological theory, like any moral theory, is an attempt to understand the putative value revealed by its characteristic emotions, this nonetheless in no way commits them to saying that these faculties are infallible or perfectly reliable, or that one’s moral intuitions are self-evidently and indefeasibly true in the strong sense of these terms. This isn’t back-pedaling; these are standard concessions by defenders of intuitions of any ethical stripe.7
With these observations behind us, let’s move to the meat of the issue, which concerns the relationship between deontological theory and emotions. My suggestion is that the deontologist should embrace the idea that deontological theory is of ‘deontological value,’ and that deontological value is revealed to us via ‘deontological emotions.’ Deontological emotions are deontological intuitions, and these intuitions—which have both particular cases and principles as their objects—at least to some degree reflect the nature of that value. The outline of such a story requires only some plausible commitments about (a) the nature of deontological value, (b) the nature of emotions, and (c) the nature of the connection between these values and the emotions. I sketch the outline of a response vis-à-vis (a) and (b) in what remains of this section, but focus in slightly more detail on the account of (c) in the next section.
The way a deontologist responds to Greene’s research will depend to some degree on how she cashes-out deontology. I cannot argue for my way of understanding deontology here, but I will help myself to this handy way of capturing characteristically deontological judgments. Suppose we distinguish between first-order and second-order values as so: ‘Axiological’ value is a first-order value—having this property makes something defeasibly worthy of promotion. Second-order value (supposing there is any) is such that the axiological value of things is defeated if they are promoted in ways failing to possess second-order value. For instance, imagine a world with lots of pleasure, excitement, and nifty toys—but all and only the unjust people have those things, while the just people are miserable. If your intuitions are like mine, that world seems worse than no world at all. The axiological goodness of those items strikes us as defeated. This suggests that we think of justice as a putative second-order value.8
Also suppose the truth of the typical position on emotions,9 according to which emotions can be rationally appraised (e.g., it is irrational to be angry at a table you have stubbed your toe on). The “cognitive” element of an emotion needn’t be a belief for our purposes, but it must be at least an
109

Dan Demetriou
appearance of a proposition’s truth. Further suppose that some emotions— anger among them—cannot be seen as rational without appealing to value in some way.
The question these assumptions jointly raise is: Which emotions are made rational by which sorts of value? After all, not all strong emotions are plausibly made rational by a second-order value. For instance, sadness, one can reasonably conclude, is made rational by a dramatic loss of axiological value; regret is made rational by an avoidable loss of axiological value, and so forth. But some emotions are apparently made rational only by a second- order value. It is a commonplace in both philosophical and empirical work on emotions that the condemnatory emotions made rational by injustice are resentment/anger and guilt.10 Recent empirical work by anthropologists and social-psychologists suggests that other “alarm bell” emotions might include horror, disgust, shame, and contempt.11
Now for Greene, the nature of an “alarm bell” emotion is what makes people who trust such emotions have non-consequentialist judgments—we don’t push the big man off the footbridge because we are horrified at the prospect, so to speak. I believe this is a significant question-begging assumption. The natural gloss is that subjects make deontological judgments because they have “alarm bell” emotions which they trust to be rational. If the view on offer is true, these “alarm bell” emotions are made rational only by an appropriate second-order disvalue.
What is left out of this picture, however, is how the deontological emotions hook up with these disvalues. There are already good accounts in the literature about how this could be the case, but let me outline what I see to be as the best strategy.
4. Modest Intuitionism
Assuming that Greene is right and that the deontologist is guided not by “reason” but by emotion, mightn’t those emotions present an appearance (however unreliably) of an extra-mental moral fact? There is a tradition, of course, which embraces seeing affect as presenting moral facts to us— “sentimentalism”—but sentimentalist accounts are usually committed to some less-than-robustly realistic metaethic (most sentimentalist accounts should be described as ‘response-dependent’ ones).12 Nonetheless, the past few years have seen a few robustly realist metaethical accounts arguing that affect reveals wholly mind-independent value. For Mark Johnston (2001) and for Graham Oddie (2005), e.g., affect quite literally provides us with a posteriori value-observations.
But in this section I wish to sketch a much more modest account of moral intuitions seen as emotional. The view outlined below is more
110

A Modest Intuitionist Reply to Greene
“modest” because it doesn’t take the perceptual analogy seriously. For it’s worth bearing in mind that if emotions really are moral senses in the way, say, touch is the modality of shape, then value-properties would have to be causally efficacious. Maybe value properties are causally efficacious, but I’m leery of making such a big commitment on behalf of moral realism. It would be better to explore a humbler view which sees emotions as generating appearances of moral fact and yet denies that moral properties make some sort of causal impact on our brains.
This desideratum takes us to rationalist realist accounts of intuitions. Realist Michael Huemer (2005), for instance, sees moral intuitions as non- inferential but defeasible “intellectual seemings” of moral truth. What makes Huemer an a priorist is that he holds that these appearances of moral truth are generated a priori. For Huemer, we can tell that there is (say) a chair before us by observing (a posteriori) that such-and-such properties are instantiated by x and that (a priori) the possession of such-and-such properties by x qualify it for counting as a chair. Likewise, by observing (a posteriori) that such-and-such descriptive properties are had by x (say, a state of affairs), we can tell that x is morally bad because we have an a priori awareness of conditions for moral goodness not satisfied by x. The realist part of this story enters in with Huemer’s realism about the connection between concepts and universals: concepts are “graspings” of universals and moral concepts are graspings of moral universals; thus by having an appearance based partially upon on one’s moral concepts one has an appearance of the relationships holding between moral and non-moral universals falling under those concepts. Like any a priori appearance, a moral intuition is better or worse in proportion to how clearly and determinately one conceptually grasps the relevant moral universals (Huemer, 2005, Ch. 5).
This all is pretty standard rationalist fare. The major empirical difficulty, as I see it, in the standard a priorist cum realist moral epistemology is that moral intuitions aren’t usually “intellectual” seemings in the same way as our intuitions about, say, which inference-patterns are valid. As Greene and other empirical researchers have helped show, moral intuiting is often a passionate affair (again, even Greene admits that even consequentialism relies upon affect, albeit not of the “alarm bell” sort).13 A utilitarian cares about maximizing utility as opposed to, say, pain because seeing someone happy doesn’t excite his negative affects in the same way seeing someone in pain does. A deontologist cares about respecting the demands of justice because of the outrage she feels when she considers ill-gotten gains. These intuitions just aren’t like our intuitions that 2+2=4 or that something cannot be all green and all red at the same time.
111

Dan Demetriou
Enter what I will call the ‘modest’ intuitionist view, which is (broadly) reminiscent of some observations of Christopher Peacocke’s on moral intuitionism.14 It is an easy, obvious, and yet under-appreciated way to unite a prioristic realism to the commonsense and perhaps empirically-verified position that moral intuitions should be identified with emotions. It goes roughly as so:
Modest intuitionism: moral intuitions are moral emotions, and moral emotions are (defeasibly) introspectively available reports of one’s introspectively unavailable moral a priori cognition.
The modest view a bit of a hybrid: it is “sentimentalist” on top (moral intuitions = moral emotions), but “rationalist” on bottom (the connection between reality and appearances is cashed-out in rationalist terms).
By “introspectively available” I mean that emotions are something which we (usually) can tell we’re having. I can tell when I’m angry; you can tell when you’re ashamed. And by seeing moral emotions as “reports of one’s introspectively unavailable moral a priori cognition” I mean that we identify certain emotions—the “moral” ones—with reports of a priori application of moral concepts which we cannot bring fully to light. This might sound exotic, but in fact nothing could be more familiar to the philosopher. Suppose you challenge a student, Jill, to say what a chair is. Jill gives certain conditions she feels fits the bill. But clever philosopher that you are, you present Jill with x (a non-prototypical chair) that lacks some conditions Jill thought to be necessary to chairness. Jill “sees” immediately, via her intuitions about chairness, that you’re right and that x is a chair after all. Jill revises her account of chairness, but you provide yet another counterexample, and so on. Try as she might, Jill cannot articulate the concept of chairness she is relying upon—but who can? For any concept of an everyday sortal, all we have are the reports provided to our conscious minds, the content of which is something on the order of “Nope, that x isn’t an F” or “Yep, that x is an F.” The concepts being exploited to generate these reports are hidden—that’s what makes conceptual analysis so difficult—but we typically trust that there are concepts behind these intuitions and that there are properties more-or-less corresponding to these concepts.
Let’s turn to the moral case. Suppose that Jack and Jill have a dinner date for Friday, but on Wednesday Jack calls Jill and cancels by telling her he “can’t make it.” Yet come Friday night Jill sees Jack having dinner with another woman too young to be his mother. Jill has certain held opinions about what counts as an unjust action, and according to her held principles Jack didn’t act unjustly. Jill takes a breath and tells herself this, but the anger swells in her chest nonetheless. The sensible thing to say about this situation
112

A Modest Intuitionist Reply to Greene
is that whatever Jill’s consciously held opinions on what she thinks is unjust, it’s fairly clear that on a deep level Jill actually does feel that Jack treated her unjustly. Jill, if she is reflective about this, will notice the cognitive dissonance. She may side against her emotion, of course; but she also might side with the emotion and revise her false beliefs about her concept of justice. The latter option is actually more reasonable if Jill considers the facts (and let’s imagine they are facts) that she is a mentally and emotionally sound person, that she is not prone to fits of anger, and that this response isn’t obviously an irrational one (as toe-stubbing anger is). Jill doesn’t know exactly what about Jack’s behavior made his action unjust—“That will take a little reflection” she tells herself. Nonetheless, she takes Jack’s behavior as a data-point which helps her better see the contours of justice, or at least her conception of that property.
Jill’s trusting her emotion in this case is epistemically warranted because the underlying process isn’t in principle any different from her trusting the reports from her non-introspective mind about what counts as a chair.15 The only salient difference in the case of morality is that the report from her non- introspectively available cognition comes in the guise of an emotion, whereas in the case of whether x counts as a chair the report comes in a non- emotional form. It is at least metaphysically possible that there are creatures whose a priori appearances are revealed to their conscious minds by emotions; so why can’t we be such creatures, especially given the empirical evidence that we do have emotional responses which we rely upon to reveal value?
5. Conclusion
With all this in mind, one struggles to see what the fMRI research on moral intuition really shows. It fails to show that because moral intuitions are emotional, realism is obviously false (as the modest intuitionist and sophisticated realist-sentimentalist accounts show). It also fails to show that since deontological intuitions are based on emotion, deontology is confabulatory. Deontology is confabulatory in exactly the same way our theory of chairness is confabulatory: we cannot articulate what chairs are or even what our own concept of CHAIR is, but we rely upon our intuitions to figure such things out. Greene’s work, if anything, is helpful to deontology by helping deontologist to see that her emotions tend to be more sensitive to determinate harm. This might teach the deontologist to be wary of her emotions—or lack of emotions—in certain cases. Or it may teach the deontologist that determinate harm is more morally relevant than indeterminate harm—who knows?16 But it doesn’t help show that deontology is false.